import os
import json
import psycopg2
from typing import Dict, List, Tuple, Optional, Any
from openai import OpenAI
import numpy as np
import uuid
import logging

try:
    from duckduckgo_search import DDGS
except ImportError:
    DDGS = None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VectorDB:
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        self.vector_db_url = os.getenv("VECTOR_DATABASE_URL")
        self.general_db_url = os.getenv("DATABASE_URL")
        self.api_key = os.getenv("OPENAI_API_KEY")
        
        if not self.vector_db_url or not self.general_db_url:
            raise ValueError("ë°ì´í„°ë² ì´ìŠ¤ URL(VECTOR_DATABASE_URL, DATABASE_URL)ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        self.client = OpenAI(api_key=self.api_key)
    
    def get_vector_connection(self):
        """Vector DB ì—°ê²°"""
        return psycopg2.connect(self.vector_db_url)

    def create_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Embedding creation failed: {e}")
            return []
    
    def save_feedback(self, feedback_id: str, user_id: str, text: str, metadata: Dict):
        """ì‚¬ìš©ì í”¼ë“œë°±(ì±„íŒ…) ì €ì¥"""
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            embedding = self.create_embedding(text)
            
            cur.execute("""
                INSERT INTO feedback_embeddings 
                (feedback_id, user_id, embedding, text, metadata)
                VALUES (%s, %s, %s, %s, %s)
            """, (
                feedback_id,
                user_id,
                embedding,
                text,
                json.dumps(metadata)
            ))
            
            conn.commit()
            cur.close()
            conn.close()
        except Exception as e:
            logger.error(f"Feedback save failed: {e}")

    def search_similar_feedbacks(self, query_text: str, user_id: str, top_k: int = 3) -> List[Dict]:
        """ìœ ì‚¬í•œ ê³¼ê±° ëŒ€í™” ê²€ìƒ‰"""
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            query_embedding = self.create_embedding(query_text)
            
            cur.execute("""
                SELECT text, metadata, embedding <=> %s::vector as distance
                FROM feedback_embeddings
                WHERE user_id = %s
                ORDER BY distance ASC
                LIMIT %s
            """, (query_embedding, user_id, top_k))
            
            results = []
            for row in cur.fetchall():
                results.append({
                    "text": row[0],
                    "metadata": row[1],
                    "distance": float(row[2])
                })
            
            cur.close()
            conn.close()
            return results
        except Exception as e:
            logger.error(f"Search feedbacks failed: {e}")
            return []

    def search_products(self, query_text: str, category: str, top_k: int = 5) -> List[Dict]:
        """
        [í•µì‹¬] ì œí’ˆ ë²¡í„° DB ê²€ìƒ‰
        """
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            query_embedding = self.create_embedding(query_text)
            
            cur.execute("""
                SELECT brand, product_name, color_name, price, text, metadata,
                       embedding <=> %s::vector as distance
                FROM product_embeddings
                WHERE category = %s
                ORDER BY distance ASC
                LIMIT %s
            """, (query_embedding, category, top_k))
            
            results = []
            for row in cur.fetchall():
                meta = row[5] if row[5] else {}
                
                results.append({
                    "brand": row[0],
                    "product_name": row[1],
                    "shade_name": row[2],
                    "price": row[3],
                    "rag_text": row[4], 
                    "metadata": meta,
                    "distance": float(row[6]),
                    "finish": meta.get("texture", "unknown") 
                })
            
            cur.close()
            conn.close()
            logger.info(f"ğŸ” [DB Search] Found {len(results)} products for query: '{query_text}'")
            return results
            
        except Exception as e:
            logger.error(f"Error searching products: {e}")
            return []


class IntentClassifier:
    def classify(self, text: str) -> str:
        # [PDF ë°˜ì˜] íŠ¸ë Œë“œ/ìœ í–‰ ê´€ë ¨ í‚¤ì›Œë“œ -> ì›¹ ê²€ìƒ‰ íŠ¸ë¦¬ê±°
        trend_keywords = ["ìœ í–‰", "íŠ¸ë Œë“œ", "ìš”ì¦˜", "ì§€ê¸ˆ ëœ¨ëŠ”", "í•«í•œ", "ì¸ê¸°", "ì‹ ìƒ"]
        if any(word in text for word in trend_keywords):
            return "trend"
            
        if any(word in text for word in ["ì™œ", "ì´ìœ ", "ì„¤ëª…", "ë­ì•¼", "ì•Œë ¤ì¤˜"]):
            return "explain"
            
        return "recommend"

class FeedbackParser:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def parse_preference(self, user_text: str) -> Dict[str, Any]:
        """
        user_textì—ì„œ í†¤/í”¼ë‹ˆì‰¬/ë°ê¸°/ì±„ë„/ì¢‹ì•„í•˜ëŠ” í‚¤ì›Œë“œ/ì‹«ì–´í•˜ëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ (LLM ì‚¬ìš©)
        """
        prompt = f"""
        ë„ˆëŠ” K-ë·°í‹° ìƒ‰ì¡° ë¶„ì„ê°€ì•¼.
        
        ì‚¬ìš©ì ë¬¸ì¥ì—ì„œ ì·¨í–¥ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.
        
        ì‚¬ìš©ì ë¬¸ì¥:
        "{user_text}"
        
        JSON í˜•ì‹:
        {{
          "tone": "cool / warm / neutral / unknown ì¤‘ í•˜ë‚˜",
          "finish": "glossy / matte / velvet / tint / unknown ì¤‘ í•˜ë‚˜",
          "brightness": "ë°ìŒ / ì¤‘ê°„ / ì–´ë‘ì›€ / unknown ì¤‘ í•˜ë‚˜",
          "saturation": "ì„ ëª… / ì€ì€ / ë®¤íŠ¸ / unknown ì¤‘ í•˜ë‚˜",
          "like_keywords": ["ì‚¬ìš©ìê°€ ì„ í˜¸í•œë‹¤ê³  ì–¸ê¸‰í•œ í‚¤ì›Œë“œ ëª©ë¡"],
          "dislike_keywords": ["ì‚¬ìš©ìê°€ í”¼í•˜ê³  ì‹¶ë‹¤ê³  í•œ í‚¤ì›Œë“œ ëª©ë¡"]
        }}
        
        ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ë§Œ ì¶œë ¥í•´.
        """

        try:
            res = self.client.chat.completions.create(
                model="gpt-4o-mini",  # gpt-4.1-miniëŠ” ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ gpt-4o-mini ì‚¬ìš©
                messages=[
                    {
                        "role": "system",
                        "content": "You must output ONLY valid JSON with the specified keys.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                max_tokens=200,
            )

            raw = res.choices[0].message.content.strip()
            
            # JSON í¬ë§·íŒ… í´ë¦°ì—… (```json ... ``` ì œê±°)
            if raw.startswith("```json"):
                raw = raw[7:]
            if raw.endswith("```"):
                raw = raw[:-3]
            raw = raw.strip()

            try:
                data = json.loads(raw)
            except Exception:
                # í˜¹ì‹œ ì•ë’¤ ì¡ë‹¤í•œ í…ìŠ¤íŠ¸ê°€ ì„ì˜€ì„ ë•Œ ëŒ€ë¹„
                start = raw.find("{")
                end = raw.rfind("}")
                if start != -1 and end != -1:
                    try:
                        data = json.loads(raw[start : end + 1])
                    except Exception:
                        data = {}
                else:
                    data = {}

        except Exception as e:
            logger.error(f"Preference parsing failed: {e}")
            data = {}

        return {
            "tone": data.get("tone", "unknown"),
            "finish": data.get("finish", "unknown"),
            "brightness": data.get("brightness", "unknown"),
            "saturation": data.get("saturation", "unknown"),
            "like_keywords": data.get("like_keywords", []),
            "dislike_keywords": data.get("dislike_keywords", []),
        }

class RAGAgent:
    def __init__(self, vector_db: VectorDB):
        self.vector_db = vector_db
        self.intent_classifier = IntentClassifier()
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ë° íŒŒì„œ ì´ˆê¸°í™”
        api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key)
        self.feedback_parser = FeedbackParser(api_key=api_key)

    def perform_web_search(self, query: str) -> str:
        """
        [PDF ë°˜ì˜] ì›¹ ê²€ìƒ‰ ë„êµ¬ (DuckDuckGo Search í™œìš©)
        """
        if DDGS is None:
            return "ì›¹ ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬(duckduckgo-search)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            logger.info(f"Web Searching for: {query}")
            
            # ê²€ìƒ‰ ì‹¤í–‰ (ìƒìœ„ 3ê°œ ê²°ê³¼)
            with DDGS() as ddgs:
                results = list(ddgs.text(query, max_results=3))
            
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì´ ì½ê¸° ì¢‹ì€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            context_text = "\n".join([
                f"- ì œëª©: {r['title']}\n  ë‚´ìš©: {r['body']}\n  ë§í¬: {r['href']}"
                for r in results
            ])
            return context_text
            
        except Exception as e:
            logger.error(f"Web Search Failed: {e}")
            return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def process_message(
        self,
        user_id: str,
        message: str,
        current_recommendations: List[Dict],
        user_profile: Dict,
        category: str
    ) -> Dict:
        # 1. ì˜ë„ íŒŒì•…
        intent = self.intent_classifier.classify(message)
        logger.info(f"ğŸ¤– User Intent: {intent}")
        
        # 2. ì„ í˜¸ë„ ì¶”ì¶œ (LLM ê¸°ë°˜)
        parsed_pref = self.feedback_parser.parse_preference(message)
        logger.info(f"ğŸ§  Parsed User Preference: {parsed_pref}")
        
        # 3. ì‚¬ìš©ì ì±„íŒ… ì €ì¥
        feedback_id = str(uuid.uuid4())
        self.vector_db.save_feedback(
            feedback_id=feedback_id,
            user_id=user_id,
            text=message,
            metadata={
                "preferences": parsed_pref,
                "category": category,
                "intent": intent,
                "timestamp": str(uuid.uuid1())
            }
        )
        
        # 4. ê³¼ê±° ëŒ€í™” ë§¥ë½ ê²€ìƒ‰
        similar_feedbacks = self.vector_db.search_similar_feedbacks(message, user_id, top_k=3)
        
        # ==================================================================
        # [ë¶„ê¸° ì²˜ë¦¬] íŠ¸ë Œë“œ ì§ˆë¬¸(ì›¹ê²€ìƒ‰) vs ì œí’ˆ ì¶”ì²œ(DBê²€ìƒ‰)
        # ==================================================================
        
        if intent == "trend":
            # (A) ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
            search_context = self.perform_web_search(message)
            
            # (B) íŠ¸ë Œë“œ ë‹µë³€ ìƒì„±
            return self.generate_trend_response(
                user_text=message,
                user_profile=user_profile,
                parsed_pref=parsed_pref,
                search_context=search_context
            )
            
        else:
            # (A) ì œí’ˆ ì¶”ì²œ (ê¸°ì¡´ ë¡œì§) - DB ê²€ìƒ‰
            # ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥: LLMì´ ì¶”ì¶œí•œ í‚¤ì›Œë“œ í™œìš©
            like_keywords_str = " ".join(parsed_pref.get('like_keywords', []))
            search_query = f"{message} {like_keywords_str} {like_keywords_str}"
            
            # DB ê²€ìƒ‰ (top_k=10)
            db_products = self.vector_db.search_products(
                query_text=search_query, 
                category=category, 
                top_k=10 
            )
            
            # ì¬ì •ë ¬ ë¡œì§ (ë§¤íŠ¸/ê¸€ë¡œì‹œ ìš°ì„ ìˆœìœ„)
            user_finish = parsed_pref.get("finish", "unknown")
            if user_finish in ["matte", "velvet"]:
                target_keywords = ["ë§¤íŠ¸", "ì„¸ë¯¸ë§¤íŠ¸", "ë³´ì†¡", "ë²¨ë²³", "ë¬´ê´‘", "íŒŒìš°ë”ë¦¬"]
                db_products.sort(
                    key=lambda x: any(k in x['rag_text'] for k in target_keywords), 
                    reverse=True
                )
            elif user_finish in ["glossy", "tint"]:
                target_keywords = ["ê¸€ë¡œì‹œ", "ì´‰ì´‰", "ê´‘íƒ", "íƒ•í›„ë£¨", "ë¬¼ë§‰", "ìˆ˜ë¶„"]
                db_products.sort(
                    key=lambda x: any(k in x['rag_text'] for k in target_keywords), 
                    reverse=True
                )
            
            final_candidates = db_products[:5]
            
            # DB ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ì¶”ì²œ ì‚¬ìš©
            if not final_candidates and current_recommendations:
                 for item in current_recommendations:
                     final_candidates.append({
                         "brand": item.get("brand", ""),
                         "product_name": item.get("product_name", ""),
                         "shade_name": item.get("shade_name", ""),
                         "rag_text": f"{item.get('brand')} {item.get('product_name')}. ê¸°ì¡´ ì¶”ì²œ ì œí’ˆì…ë‹ˆë‹¤.",
                         "price": item.get("price", 0),
                         "finish": item.get("finish", "unknown")
                     })

            # (B) ì¶”ì²œ ë‹µë³€ ìƒì„±
            return self.generate_explanation(
                user_text=message,
                user_profile=user_profile,
                parsed_pref=parsed_pref,
                memories=similar_feedbacks,
                candidate_products=final_candidates
            )

    def generate_trend_response(
        self,
        user_text: str,
        user_profile: Dict,
        parsed_pref: Dict,
        search_context: str
    ) -> Dict:
        """ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë Œë“œ ì •ë³´ë¥¼ ì„¤ëª…í•˜ëŠ” ë‹µë³€ ìƒì„±"""
        
        system_prompt = f"""
        ë‹¹ì‹ ì€ ìµœì‹  K-Beauty íŠ¸ë Œë“œë¥¼ ê¿°ëš«ê³  ìˆëŠ” ë·°í‹° ì—ë””í„°ì…ë‹ˆë‹¤.
        ì œê³µëœ [ì›¹ ê²€ìƒ‰ ê²°ê³¼]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
        
        [ì‚¬ìš©ì í”„ë¡œí•„]
        - í†¤: {user_profile.get('tone', 'ì•Œ ìˆ˜ ì—†ìŒ')}
        - ê´€ì‹¬ì‚¬: {user_text}
        
        [ì›¹ ê²€ìƒ‰ ê²°ê³¼]
        {search_context}
        
        [ì§€ì‹œì‚¬í•­]
        1. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì–¸ê¸‰ë˜ëŠ” í•µì‹¬ íŠ¸ë Œë“œ(ìƒ‰ìƒ, ì œí˜•, ë¸Œëœë“œ ë“±)ë¥¼ ìš”ì•½í•˜ì„¸ìš”.
        2. ì‚¬ìš©ìì˜ í”„ë¡œí•„(í¼ìŠ¤ë„ ì»¬ëŸ¬ ë“±)ê³¼ ì—°ê´€ ì§€ì–´ íŒì„ ì£¼ì„¸ìš”. (ì˜ˆ: "ìš”ì¦˜ ê¸€ë¡œì‹œ ë¦½ì´ ìœ í–‰ì¸ë°, ê³ ê°ë‹˜ ê°™ì€ ì—¬ì¿¨ì—ê² ì´ëŸ° í•‘í¬ê°€ ì¢‹ì•„ìš”")
        3. ê²€ìƒ‰ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì¼ë°˜ì ì¸ ìµœì‹  ë·°í‹° ìƒì‹ìœ¼ë¡œ ë‹µë³€í•˜ë˜, ì¶œì²˜ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
        4. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°(í•´ìš”ì²´)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_text}
                ],
                temperature=0.7
            )
            return {
                "success": True,
                "intent": "trend",
                "assistant_message": response.choices[0].message.content,
                "recommendations": [], 
                "parsed_preferences": parsed_pref
            }
        except Exception as e:
            logger.error(f"Trend generation failed: {e}")
            return {
                "success": False,
                "intent": "error",
                "assistant_message": "ìµœì‹  íŠ¸ë Œë“œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "recommendations": [],
                "parsed_preferences": parsed_pref
            }

    def generate_explanation(
        self,
        user_text: str,
        user_profile: Dict,
        parsed_pref: Dict,
        memories: List[Dict],
        candidate_products: List[Dict]
    ) -> Dict:
        
        if candidate_products:
            products_context = "\n".join([
                f"""
                [ì œí’ˆ {idx+1}]
                - ë¸Œëœë“œ: {p['brand']}
                - ì´ë¦„: {p['product_name']} ({p['shade_name']})
                - ê°€ê²©: {p['price']}ì›
                - ìƒì„¸ì •ë³´/ë¦¬ë·°ìš”ì•½: {p.get('rag_text', 'ì •ë³´ ì—†ìŒ')}
                """ for idx, p in enumerate(candidate_products)
            ])
        else:
            products_context = "ê²€ìƒ‰ëœ ì í•©í•œ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        system_prompt = f"""
        ë‹¹ì‹ ì€ ìœµí†µì„± ìˆê³  ì„¤ë“ë ¥ ìˆëŠ” K-Beauty AI ë·°í‹° ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
        ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , í¼ìŠ¤ë„ ì»¬ëŸ¬ ì „ë¬¸ê°€ì²˜ëŸ¼ ì‚¬ìš©ìë¥¼ ì„¤ë“í•˜ì„¸ìš”.

        [ì‚¬ìš©ì í”„ë¡œí•„]
        - í¼ìŠ¤ë„ ì»¬ëŸ¬: {user_profile.get('tone', 'ì•Œ ìˆ˜ ì—†ìŒ')}
        - ì„ í˜¸ ë¸Œëœë“œ: {', '.join(user_profile.get('fav_brands', []))}
        - ì„ í˜¸ í”¼ë‹ˆì‹œ: {', '.join(user_profile.get('finish_preference', []))}
        
        [í˜„ì¬ ëŒ€í™”ì—ì„œ íŒŒì•…ëœ ì‚¬ìš©ì ì˜ë„]
        - ì›í•˜ëŠ” í†¤: {parsed_pref.get('tone')}
        - ì›í•˜ëŠ” í”¼ë‹ˆì‹œ: {parsed_pref.get('finish')}
        - ì„ í˜¸ í‚¤ì›Œë“œ: {', '.join(parsed_pref.get('like_keywords', []))}
        
        [ê²€ìƒ‰ëœ í›„ë³´ ì œí’ˆ ëª©ë¡ (DB ê¸°ë°˜)]
        {products_context}
        
        [ì‚¬ìš©ì ì§ˆë¬¸/ë¶ˆë§Œ]
        "{user_text}"
        
        [í–‰ë™ ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)]
        1. **'ì¶”ì²œ ë¶ˆê°€'ë¼ê³  ë§í•˜ì§€ ë§ˆì„¸ìš”.** í›„ë³´ ì œí’ˆ ëª©ë¡ ì¤‘ì—ì„œ ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­(í…ìŠ¤ì²˜, ìƒ‰ê° ë“±)ì— **ê°€ì¥ ê·¼ì ‘í•œ 1~3ê°œ**ë¥¼ ë°˜ë“œì‹œ ê³¨ë¼ë‚´ì„¸ìš”.
        
        2. **'í†¤ í¬ë¡œìŠ¤(Tone-Cross)'ì™€ 'ìœ ì‚¬ ì†ì„±'ì„ í—ˆìš©í•˜ì„¸ìš”.**
           - ì‚¬ìš©ìê°€ 'ë§¤íŠ¸'ë¥¼ ì›í•˜ëŠ”ë° ê²€ìƒ‰ ê²°ê³¼ì— 'ì„¸ë¯¸ë§¤íŠ¸'ë‚˜ 'ë²¨ë²³'ë§Œ ìˆë‹¤ë©´? -> "ì™„ì „í•œ ë§¤íŠ¸ëŠ” ì•„ë‹ˆì§€ë§Œ, ì†ì€ ì´‰ì´‰í•˜ê³  ê²‰ì€ ë³´ì†¡í•œ **ì„¸ë¯¸ë§¤íŠ¸** ì œí˜•ì´ë¼ ê³ ê°ë‹˜ê»˜ ë” ì˜ ë§ì„ ìˆ˜ ìˆì–´ìš”!"ë¼ê³  ì„¤ë“í•˜ì„¸ìš”.

        3. **ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.**
           - ì œí’ˆ ì •ë³´(rag_text)ì— ìˆëŠ” "ê°ì§ˆ ë¶€ê° ì—†ìŒ", "ì§€ì†ë ¥ ì¢‹ìŒ" ë“±ì˜ ë©˜íŠ¸ë¥¼ ì¸ìš©í•´ì„œ ì¶”ì²œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
           
        4. ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ê³µê°í•˜ëŠ” ë§íˆ¬(í•´ìš”ì²´)ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_text}
                ],
                temperature=0.7 
            )
            
            assistant_message = response.choices[0].message.content
            
            return {
                "assistant_message": assistant_message,
                "recommendations": candidate_products[:3], 
                "parsed_preferences": parsed_pref,
                "intent": "recommend"
            }
            
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")
            return {
                "assistant_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.",
                "recommendations": [],
                "parsed_preferences": parsed_pref,
                "intent": "error"
            }