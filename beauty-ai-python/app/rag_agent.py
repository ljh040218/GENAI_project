import os
import json
import psycopg2
from typing import Dict, List, Tuple, Optional, Any
from openai import OpenAI
import numpy as np
import uuid
import logging

try:
    from duckduckgo_search import DDGS
except ImportError:
    DDGS = None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def normalize_category(value: str) -> str:
    if not value:
        return "unknown"

    value = value.lower()

    mapping = {
        "lips": ["lip", "lips", "ë¦½", "ë¦½ìŠ¤í‹±", "í‹´íŠ¸", "ë¦½ë°¤", "ê¸€ë¡œìŠ¤"],
        "cheeks": ["cheek", "cheeks", "ì¹˜í¬", "ë¸”ëŸ¬ì…”", "ë³¼"],
        "eyes": ["eye", "eyes", "ì•„ì´", "ì„€ë„ìš°", "íŒ”ë ˆíŠ¸", "ëˆˆ"]
    }

    for k, aliases in mapping.items():
        if value in aliases:
            return k

    return "unknown"
    
class VectorDB:
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        self.vector_db_url = os.getenv("VECTOR_DATABASE_URL")
        self.general_db_url = os.getenv("DATABASE_URL")
        self.api_key = os.getenv("OPENAI_API_KEY")
        
        if not self.vector_db_url or not self.general_db_url:
            raise ValueError("ë°ì´í„°ë² ì´ìŠ¤ URL(VECTOR_DATABASE_URL, DATABASE_URL)ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        self.client = OpenAI(api_key=self.api_key)
    
    def get_vector_connection(self):
        """Vector DB ì—°ê²°"""
        return psycopg2.connect(self.vector_db_url)

    def create_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Embedding creation failed: {e}")
            return []
    
    def save_feedback(self, feedback_id: str, user_id: str, text: str, metadata: Dict):
        """ì‚¬ìš©ì í”¼ë“œë°±(ì±„íŒ…) ì €ì¥"""
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            embedding = self.create_embedding(text)
            
            cur.execute("""
                INSERT INTO feedback_embeddings 
                (feedback_id, user_id, embedding, text, metadata)
                VALUES (%s, %s, %s, %s, %s)
            """, (
                feedback_id,
                user_id,
                embedding,
                text,
                json.dumps(metadata)
            ))
            
            conn.commit()
            cur.close()
            conn.close()
        except Exception as e:
            logger.error(f"Feedback save failed: {e}")

    def search_similar_feedbacks(self, query_text: str, user_id: str, top_k: int = 3) -> List[Dict]:
        """ìœ ì‚¬í•œ ê³¼ê±° ëŒ€í™” ê²€ìƒ‰"""
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            query_embedding = self.create_embedding(query_text)
            
            cur.execute("""
                SELECT text, metadata, embedding <=> %s::vector as distance
                FROM feedback_embeddings
                WHERE user_id = %s
                ORDER BY distance ASC
                LIMIT %s
            """, (query_embedding, user_id, top_k))
            
            results = []
            for row in cur.fetchall():
                results.append({
                    "text": row[0],
                    "metadata": row[1],
                    "distance": float(row[2])
                })
            
            cur.close()
            conn.close()
            return results
        except Exception as e:
            logger.error(f"Search feedbacks failed: {e}")
            return []

    def search_products(self, query_text: str, category: str, top_k: int = 5) -> List[Dict]:
        """
        [í•µì‹¬] ì œí’ˆ ë²¡í„° DB ê²€ìƒ‰
        """
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            query_embedding = self.create_embedding(query_text)
            
            # categoryê°€ 'unknown'ì¸ ê²½ìš° WHERE ì ˆì—ì„œ ì œì™¸í•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ ë„“í˜ (ì„ íƒì )
            # í˜„ì¬ëŠ” ì •í™•ì„±ì„ ìœ„í•´ WHERE category = %s ìœ ì§€
            if category == "unknown":
                 logger.warning("Category is 'unknown'. Searching without category filter.")
                 # ì¹´í…Œê³ ë¦¬ í•„í„° ì—†ì´ ê²€ìƒ‰í•˜ëŠ” ê²½ìš°:
                 cur.execute("""
                    SELECT brand, product_name, color_name, price, text, metadata,
                           embedding <=> %s::vector as distance
                    FROM product_embeddings
                    ORDER BY distance ASC
                    LIMIT %s
                 """, (query_embedding, top_k))
            else:
                cur.execute("""
                    SELECT brand, product_name, color_name, price, text, metadata,
                           embedding <=> %s::vector as distance
                    FROM product_embeddings
                    WHERE category = %s
                    ORDER BY distance ASC
                    LIMIT %s
                """, (query_embedding, category, top_k))
            
            results = []
            for row in cur.fetchall():
                meta = row[5] if row[5] else {}
                
                results.append({
                    # NULL ê°’(NoneType)ì´ .lower()ì—ì„œ ì˜¤ë¥˜ë¥¼ ì¼ìœ¼í‚¤ì§€ ì•Šë„ë¡ ì•ˆì „í•˜ê²Œ ë³€í™˜
                    "brand": str(row[0]) if row[0] is not None else "",
                    "product_name": str(row[1]) if row[1] is not None else "",
                    "shade_name": str(row[2]) if row[2] is not None else "",
                    "price": row[3],
                    "rag_text": str(row[4]) if row[4] is not None else "", 
                    "metadata": meta,
                    "distance": float(row[6]),
                    "finish": meta.get("texture", "unknown") 
                })
            
            cur.close()
            conn.close()
            logger.info(f"ğŸ” [DB Search] Found {len(results)} products for query: '{query_text}' in category: '{category}'")
            return results
            
        except Exception as e:
            logger.error(f"Error searching products: {e}")
            return []

class IntentClassifier:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key)

    def classify(self, user_message: str) -> str:
        prompt = f"""
        ì‚¬ìš©ì ë©”ì‹œì§€: "{user_message}"
        
        ìœ„ ë©”ì‹œì§€ì˜ ì˜ë„ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´:
        - "trend": ìµœì‹  ë·°í‹° íŠ¸ë Œë“œ, ìœ í–‰ ì •ë³´, ì‹œì¦Œë³„ íŠ¸ë Œë“œ ì§ˆë¬¸
        - "explain": MLBB, ì¿¨í†¤/ì›œí†¤, ì±„ë„, í†¤ í¬ë¡œìŠ¤ ë“± ìƒ‰ì¡° ì´ë¡ /ê°œë… ì„¤ëª… ìš”ì²­
        - "recommend": ì œí’ˆ ì¶”ì²œ ë˜ëŠ” ì¬ì¶”ì²œ ìš”ì²­ (ê¸°ë³¸ê°’)
        
        JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
        {{
          "intent": "trend / explain / recommend ì¤‘ í•˜ë‚˜"
        }}
        """

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You must output ONLY valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=50
            )

            raw = response.choices[0].message.content.strip()

            if raw.startswith("```json"):
                raw = raw[7:]
            if raw.endswith("```"):
                raw = raw[:-3]
            raw = raw.strip()

            try:
                data = json.loads(raw)
                intent = data.get("intent", "recommend")
            except:
                start = raw.find("{")
                end = raw.rfind("}")
                if start != -1 and end != -1:
                    try:
                        data = json.loads(raw[start:end+1])
                        intent = data.get("intent", "recommend")
                    except:
                        intent = "recommend"
                else:
                    intent = "recommend"

            if intent not in ["trend", "explain", "recommend"]:
                intent = "recommend"

            return intent

        except Exception as e:
            logger.error(f"Intent classification failed: {e}")
            return "recommend"


class FeedbackParser:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def parse_preference(self, user_text: str) -> Dict[str, Any]:
        """
        user_textì—ì„œ í†¤/í”¼ë‹ˆì‰¬/ë°ê¸°/ì±„ë„/ì¢‹ì•„í•˜ëŠ” í‚¤ì›Œë“œ/ì‹«ì–´í•˜ëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ (LLM ì‚¬ìš©)
        """
        prompt = f"""
        ë„ˆëŠ” K-ë·°í‹° ìƒ‰ì¡° ë¶„ì„ê°€ì•¼.
        
        ì‚¬ìš©ì ë¬¸ì¥ì—ì„œ ì·¨í–¥ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.
        
        ì‚¬ìš©ì ë¬¸ì¥:
        "{user_text}"
        
        JSON í˜•ì‹:
        {{
          "tone": "cool / warm / neutral / unknown ì¤‘ í•˜ë‚˜",
          "finish": "glossy / matte / velvet / tint / unknown ì¤‘ í•˜ë‚˜",
          "category": "lips / cheeks / eyes / unknown ì¤‘ í•˜ë‚˜",
          "brightness": "ë°ìŒ / ì¤‘ê°„ / ì–´ë‘ì›€ / unknown ì¤‘ í•˜ë‚˜",
          "saturation": "ì„ ëª… / ì€ì€ / ë®¤íŠ¸ / unknown ì¤‘ í•˜ë‚˜",
          "like_keywords": ["ì‚¬ìš©ìê°€ ì„ í˜¸í•œë‹¤ê³  ì–¸ê¸‰í•œ í‚¤ì›Œë“œ ëª©ë¡"],
          "dislike_keywords": ["ì‚¬ìš©ìê°€ í”¼í•˜ê³  ì‹¶ë‹¤ê³  í•œ í‚¤ì›Œë“œ ëª©ë¡"]
        }}
        
        ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ë§Œ ì¶œë ¥í•´.
        """

        try:
            res = self.client.chat.completions.create(
                model="gpt-4o-mini",  # gpt-4.1-miniëŠ” ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ gpt-4o-mini ì‚¬ìš©
                messages=[
                    {
                        "role": "system",
                        "content": "You must output ONLY valid JSON with the specified keys.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                max_tokens=200,
            )

            raw = res.choices[0].message.content.strip()
            
            # JSON í¬ë§·íŒ… í´ë¦°ì—… (```json ... ``` ì œê±°)
            if raw.startswith("```json"):
                raw = raw[7:]
            if raw.endswith("```"):
                raw = raw[:-3]
            raw = raw.strip()

            try:
                data = json.loads(raw)
            except Exception:
                # í˜¹ì‹œ ì•ë’¤ ì¡ë‹¤í•œ í…ìŠ¤íŠ¸ê°€ ì„ì˜€ì„ ë•Œ ëŒ€ë¹„
                start = raw.find("{")
                end = raw.rfind("}")
                if start != -1 and end != -1:
                    try:
                        data = json.loads(raw[start : end + 1])
                    except Exception:
                        data = {}
                else:
                    data = {}

        except Exception as e:
            logger.error(f"Preference parsing failed: {e}")
            data = {}

        return {
            "tone": data.get("tone", "unknown"),
            "finish": data.get("finish", "unknown"),
            "category": normalize_category(data.get("category")),
            "brightness": data.get("brightness", "unknown"),
            "saturation": data.get("saturation", "unknown"),
            "like_keywords": data.get("like_keywords", []),
            "dislike_keywords": data.get("dislike_keywords", []),
        }

class RAGAgent:
    def __init__(self, vector_db: VectorDB):
        self.vector_db = vector_db
        self.intent_classifier = IntentClassifier()
        
        api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key)
        self.feedback_parser = FeedbackParser(api_key=api_key)

    def perform_web_search(self, query: str) -> str:
        if DDGS is None:
            return "ì›¹ ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬(duckduckgo-search)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            logger.info(f"Web Searching for: {query}")
            
            with DDGS() as ddgs:
                results = list(ddgs.text(query, max_results=3))
            
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            context_text = "\n".join([
                f"- ì œëª©: {r['title']}\n  ë‚´ìš©: {r['body']}\n  ë§í¬: {r['href']}"
                for r in results
            ])
            return context_text
            
        except Exception as e:
            logger.error(f"Web Search Failed: {e}")
            return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def process_message(
        self,
        user_id: str,
        message: str,
        current_recommendations: List[Dict],
        user_profile: Dict,
        category: str # <--- ì´ ì¸ìëŠ” ê¸°ì¡´ APIì˜ ê¸°ë³¸ê°’ì¼ ìˆ˜ ìˆìŒ
    ) -> Dict:
        intent = self.intent_classifier.classify(message)
        logger.info(f"ğŸ¤– User Intent: {intent}")

        parsed_pref = self.feedback_parser.parse_preference(message)
        logger.info(f"ğŸ§  Parsed User Preference: {parsed_pref}")
        
        # ğŸŒŸ í•µì‹¬ ìˆ˜ì •: ì‚¬ìš©ìê°€ ë©”ì‹œì§€ì—ì„œ ìš”ì²­í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©
        search_category = parsed_pref.get("category", "unknown")
        if search_category == "unknown":
            # ë©”ì‹œì§€ì—ì„œ ì¹´í…Œê³ ë¦¬ íŒŒì•…ì´ ì•ˆë˜ë©´, APIì— ì „ë‹¬ëœ ê¸°ë³¸ category ì¸ì ì‚¬ìš© (ì˜ˆ: 'lips')
            search_category = category
            
        logger.info(f"ğŸ” Final Search Category determined: {search_category}")


        feedback_id = str(uuid.uuid4())
        self.vector_db.save_feedback(
            feedback_id=feedback_id,
            user_id=user_id,
            text=message,
            metadata={
                "preferences": parsed_pref,
                # DB ì €ì¥ ì‹œì—ëŠ” ë©”ì‹œì§€ì—ì„œ íŒŒì•…ëœ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
                "category": parsed_pref.get("category", "unknown"), 
                "intent": intent,
                "timestamp": str(uuid.uuid1())
            }
        )

        similar_feedbacks = self.vector_db.search_similar_feedbacks(message, user_id, top_k=3)

        if intent == "trend":
            search_context = self.perform_web_search(message)
            return self.generate_trend_response(
                user_text=message,
                user_profile=user_profile,
                parsed_pref=parsed_pref,
                search_context=search_context
            )

        if intent == "explain":
            return self.generate_explain_response(
                user_text=message,
                user_profile=user_profile,
                parsed_pref=parsed_pref,
                memories=similar_feedbacks
            )

        like_keywords_str = " ".join(parsed_pref.get('like_keywords', []))
        search_query = f"{message} {like_keywords_str} {like_keywords_str}"

        db_products = self.vector_db.search_products(
            query_text=search_query,
            category=search_category, # ğŸŒŸ ìˆ˜ì •ëœ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
            top_k=20
        )

        for p in db_products:
            p["score"] = self.score_product(
                product=p,
                parsed_pref=parsed_pref,
                user_profile=user_profile,
            )

        db_products.sort(key=lambda x: x.get("score", 0.0), reverse=True)
        final_candidates = db_products[:5]

        if not final_candidates and current_recommendations:
            for item in current_recommendations:
                final_candidates.append({
                    "brand": item.get("brand", ""),
                    "product_name": item.get("product_name", ""),
                    "shade_name": item.get("shade_name", ""),
                    "rag_text": f"{item.get('brand')} {item.get('product_name')}. ê¸°ì¡´ ì¶”ì²œ ì œí’ˆì…ë‹ˆë‹¤.",
                    "price": item.get("price", 0),
                    "finish": item.get("finish", "unknown")
                })

        return self.generate_recommend_response(
            user_text=message,
            user_profile=user_profile,
            parsed_pref=parsed_pref,
            memories=similar_feedbacks,
            candidate_products=final_candidates
        )

    def score_product(
        self,
        product: Dict,
        parsed_pref: Dict,
        user_profile: Dict
    ) -> float:
        score = 0.0

        user_tone = user_profile.get("tone", "").lower()
        pref_tone = parsed_pref.get("tone", "").lower()
        product_metadata = product.get("metadata", {})
        
        if isinstance(product_metadata, str):
            try:
                product_metadata = json.loads(product_metadata)
            except:
                product_metadata = {}

        product_pc = product_metadata.get("personal_color", "")
        
        # 1. ì¼ë°˜ í‚¤ì›Œë“œ ì ìˆ˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        # rag_textëŠ” VectorDB.search_productsì—ì„œ NoneType ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ë„ë¡ ìˆ˜ì •ë¨
        rag_text_lower = product.get("rag_text", "").lower()
        
        for keyword in parsed_pref.get("like_keywords", []):
            if keyword.lower() in rag_text_lower:
                score += 1.5
        
        for keyword in parsed_pref.get("dislike_keywords", []):
            if keyword.lower() in rag_text_lower:
                score -= 2.0

        # 2. ğŸŒŸ í•µì‹¬ ìˆ˜ì •: ì„ í˜¸ ë¸Œëœë“œ/ëª…ì‹œì  ë¸Œëœë“œ ì–¸ê¸‰ì— ê°•ë ¥í•œ ê°€ì‚°ì  ë¶€ì—¬
        
        # 2-1. ì‚¬ìš©ì í”„ë¡œí•„ì˜ ì„ í˜¸ ë¸Œëœë“œ
        fav_brands = [b.lower() for b in user_profile.get("fav_brands", [])]
        # brandëŠ” VectorDB.search_productsì—ì„œ NoneType ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ë„ë¡ ìˆ˜ì •ë¨
        product_brand = product.get("brand", "").lower()
        
        if product_brand in fav_brands:
            score += 3.0 # í”„ë¡œí•„ ì„ í˜¸ ë¸Œëœë“œì— ë†’ì€ ê°€ì‚°ì 
            
        # 2-2. ëŒ€í™”ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ë¸Œëœë“œ í‚¤ì›Œë“œ
        # 'í¬ë¦¬ë‹ˆí¬ ë¸”ëŸ¬ì…” ì¶”ì²œí•´ì¤˜'ì²˜ëŸ¼ í‚¤ì›Œë“œì— ë¸Œëœë“œê°€ í¬í•¨ë  ê²½ìš°
        brand_keywords = ["í¬ë¦¬ë‹ˆí¬", "ë§¥", "ìƒ¤ë„¬"] # ìì£¼ ì–¸ê¸‰ë  ìˆ˜ ìˆëŠ” ë¸Œëœë“œ ëª©ë¡ (ì˜ˆì‹œ)
        explicit_keywords = parsed_pref.get("like_keywords", [])
        
        for keyword in explicit_keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in brand_keywords or keyword_lower == product_brand:
                # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ìš”êµ¬í•œ ë¸Œëœë“œì— ë§¤ìš° ë†’ì€ ê°€ì‚°ì 
                score += 5.0 
                break # í•˜ë‚˜ì˜ ë¸Œëœë“œë§Œ ë§¤ì¹­ë˜ì–´ë„ ì¶©ë¶„
                
        # 3. í†¤ ë§¤ì¹­ ë¡œì§ (í•„ìš”í•˜ë‹¤ë©´ ì¶”ê°€)
        # ì˜ˆ: user_toneê³¼ product_pcê°€ ì¼ì¹˜í•˜ë©´ score += 1.0 (í˜„ì¬ëŠ” ì œì™¸í•˜ê³  ìš”ì²­ ë¬¸ì œë§Œ í•´ê²°)
        
        return score

    def generate_recommend_response(
        self,
        user_text: str,
        user_profile: Dict,
        parsed_pref: Dict,
        memories: List[Dict],
        candidate_products: List[Dict]
    ) -> Dict:
        top_candidates = candidate_products[:2] if candidate_products else []

        if top_candidates:
            products_context = "\n".join([
                f"""
[ì œí’ˆ {idx+1}]
- ë¸Œëœë“œ: {p['brand']}
- ì´ë¦„: {p['product_name']} ({p['shade_name']})
- ê°€ê²©: {p['price']}ì›
- ìƒì„¸ì •ë³´/ë¦¬ë·°ìš”ì•½: {p.get('rag_text', 'ì •ë³´ ì—†ìŒ')}
""" for idx, p in enumerate(top_candidates)
            ])
        else:
            products_context = "ê²€ìƒ‰ëœ ì í•©í•œ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        system_prompt = f"""
ë‹¹ì‹ ì€ ìœµí†µì„± ìˆê³  ì„¤ë“ë ¥ ìˆëŠ” K-Beauty AI ë·°í‹° ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ë‹¨ìˆœ ì •ë³´ ë‚˜ì—´ì´ ì•„ë‹ˆë¼, í¼ìŠ¤ë„ ì»¬ëŸ¬ ì „ë¬¸ê°€ì²˜ëŸ¼ ì‚¬ìš©ìë¥¼ ì„¤ë“í•´ì•¼ í•©ë‹ˆë‹¤.

[ì‚¬ìš©ì í”„ë¡œí•„]
- í¼ìŠ¤ë„ ì»¬ëŸ¬: {user_profile.get('tone', 'ì•Œ ìˆ˜ ì—†ìŒ')}
- ì„ í˜¸ ë¸Œëœë“œ: {', '.join(user_profile.get('fav_brands', []))}
- ì„ í˜¸ í”¼ë‹ˆì‹œ: {', '.join(user_profile.get('finish_preference', []))}

[í˜„ì¬ ëŒ€í™”ì—ì„œ íŒŒì•…ëœ ì‚¬ìš©ì ì˜ë„]
- ì›í•˜ëŠ” í†¤: {parsed_pref.get('tone')}
- ì›í•˜ëŠ” í”¼ë‹ˆì‹œ: {parsed_pref.get('finish')}
- ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ : {parsed_pref.get('category')}
- ì„ í˜¸ í‚¤ì›Œë“œ: {', '.join(parsed_pref.get('like_keywords', []))}

[í›„ë³´ ì œí’ˆ ëª©ë¡ (DB ê¸°ë°˜)]
{products_context}

[ì‚¬ìš©ì ì§ˆë¬¸/ë¶ˆë§Œ]
"{user_text}"

[ë‹µë³€ í˜•ì‹ ê·œì¹™ - ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ]
1) ë°˜ë“œì‹œ í•œêµ­ì–´(í•´ìš”ì²´)ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
2) ë‹µë³€ì€ í•˜ë‚˜ì˜ ê¸´ ë©”ì‹œì§€ë¡œ ì‘ì„±í•˜ë˜, ë‹¤ìŒ 3ê°œ ë‹¨ë½ êµ¬ì¡°ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
   - 1ë‹¨ë½: ì‚¬ìš©ìì˜ ìš”ì²­ê³¼ ìƒí™©ì„ ê³µê°í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.
   - 2ë‹¨ë½: ì¶”ì²œ ì œí’ˆ 1ë²ˆ(ì œí’ˆ 1ê°œ)ì— ëŒ€í•´,
     - ì–´ë–¤ ì ì´ ì‚¬ìš©ìì˜ í”¼ë“œë°±/ì·¨í–¥ì— ì˜ ë§ëŠ”ì§€,
     - ì œí˜•, ì»¬ëŸ¬ í†¤, ì±„ë„, ê°ì§ˆ ë¶€ê° ì—¬ë¶€ ë“± êµ¬ì²´ì ì¸ ì¥ì ì„ ë“¤ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.
   - 3ë‹¨ë½: ì¶”ì²œ ì œí’ˆ 2ë²ˆ(ì œí’ˆ 1ê°œ)ì— ëŒ€í•´,
     - 2ë‹¨ë½ê³¼ëŠ” ì¡°ê¸ˆ ë‹¤ë¥¸ í¬ì¸íŠ¸(ì˜ˆ: ë°ì¼ë¦¬/í–‰ì‚¬ìš©, ì±„ë„ ì°¨ì´)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ê³ 
     - ì–´ë–¤ ìƒí™©ì—ì„œ 2ë²ˆì„ ë” ì¶”ì²œí•˜ëŠ”ì§€ ì •ë¦¬í•´ ì¤ë‹ˆë‹¤.
3) í›„ë³´ ë¦¬ìŠ¤íŠ¸ì— **ì—†ëŠ”** ë¸Œëœë“œëª…ì´ë‚˜ ì œí’ˆëª…ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
4) ì¶”ì²œ ì œí’ˆì€ ìµœëŒ€ 2ê°œê¹Œì§€ì…ë‹ˆë‹¤.
   - í›„ë³´ê°€ 2ê°œ ì´ìƒì´ë©´, ìƒìœ„ 2ê°œë§Œ ê³¨ë¼ì„œ ì¶”ì²œí•©ë‹ˆë‹¤.
   - í›„ë³´ê°€ 1ê°œ ë¿ì´ë¼ë©´, 2ë‹¨ë½ì—ì„œ ê·¸ ì œí’ˆë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•˜ê³ 
     3ë‹¨ë½ì—ì„œëŠ” "ì´ ì œí’ˆ í•˜ë‚˜ë§Œìœ¼ë¡œë„ ì¶©ë¶„í•œ ì´ìœ "ë‚˜ í™œìš© íŒì„ ì„¤ëª…í•©ë‹ˆë‹¤.
5) 'ì¶”ì²œ ë¶ˆê°€'ë¼ëŠ” í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ ,
   í•­ìƒ í›„ë³´ ì¤‘ì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ë” ë‚˜ì€ ì„ íƒì§€ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
6) ì œí’ˆ ì„¤ëª…ì—ëŠ” ìœ„ [í›„ë³´ ì œí’ˆ ëª©ë¡]ì— í¬í•¨ëœ ì •ë³´(ë¸Œëœë“œ/ì œí’ˆëª…/ì»¬ëŸ¬/ìš”ì•½ ì •ë³´)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
7) ë¬¸ë‹¨ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„(í•œ ì¤„ ê°œí–‰)ì„ ë„£ì–´ ìì—°ìŠ¤ëŸ½ê²Œ êµ¬ë¶„í•´ ì£¼ì„¸ìš”.
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_text}
                ],
                temperature=0.7
            )

            assistant_message = response.choices[0].message.content

            return {
                "assistant_message": assistant_message,
                "recommendations": top_candidates,
                "parsed_preferences": parsed_pref,
                "intent": "recommend"
            }
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")
            return {
                "assistant_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¬ì¶”ì²œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.",
                "recommendations": [],
                "parsed_preferences": parsed_pref,
                "intent": "error"
            }

    def generate_explain_response(
        self,
        user_text: str,
        user_profile: Dict,
        parsed_pref: Dict,
        memories: List[Dict]
    ) -> Dict:
        system_prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ì— ëŠ¥ìˆ™í•œ K-Beauty ìƒ‰ì¡° ì´ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°œë…ì„ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•´ì£¼ëŠ” ì—­í• ì…ë‹ˆë‹¤.

[ì‚¬ìš©ì í”„ë¡œí•„]
- í¼ìŠ¤ë„ ì»¬ëŸ¬(ìˆë‹¤ë©´): {user_profile.get('tone', 'ì•Œ ìˆ˜ ì—†ìŒ')}

[í˜„ì¬ ëŒ€í™”ì—ì„œ íŒŒì•…ëœ ì‚¬ìš©ì ì˜ë„]
- ì›í•˜ëŠ” í†¤: {parsed_pref.get('tone')}
- ì›í•˜ëŠ” í”¼ë‹ˆì‹œ: {parsed_pref.get('finish')}
- ì„ í˜¸ í‚¤ì›Œë“œ: {', '.join(parsed_pref.get('like_keywords', []))}

[ë‹µë³€ í˜•ì‹ ê·œì¹™]
1) ë°˜ë“œì‹œ í•œêµ­ì–´(í•´ìš”ì²´)ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
2) ì œí’ˆì„ ì§ì ‘ ì¶”ì²œí•˜ê±°ë‚˜, êµ¬ì²´ì ì¸ ë¸Œëœë“œ/ì œí’ˆëª…ì„ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
3) ëŒ€ì‹ , ì‚¬ìš©ìê°€ í—·ê°ˆë ¤í•˜ëŠ” ê°œë…(ì˜ˆ: MLBB, ì¿¨í†¤/ì›œí†¤, ì±„ë„, í†¤ í¬ë¡œìŠ¤ ë“±)ì„
   - ì‰¬ìš´ ì˜ˆì‹œ,
   - ë¹„êµ ì„¤ëª…,
   - ì‹¤ì œ ë©”ì´í¬ì—… ìƒí™© ì˜ˆì‹œ
   ë¥¼ í™œìš©í•´ì„œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
4) ë§ˆì§€ë§‰ ë¶€ë¶„ì—ëŠ” ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì œí’ˆì„ ê³ ë¥¼ ë•Œ ì ìš©í•  ìˆ˜ ìˆëŠ”
   ê°„ë‹¨í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ë‚˜ íŒ(ì˜ˆ: "í…ŒìŠ¤íŠ¸í•´ë³¼ ë•Œ ì´ëŸ° ì ì„ í™•ì¸í•´ë³´ì„¸ìš”")ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”.
5) ë§íˆ¬ëŠ” ì¹œì ˆí•˜ê³  ë¶€ë‹´ìŠ¤ëŸ½ì§€ ì•Šê²Œ, ë·°í‹° ìœ íŠœë²„ê°€ ì„¤ëª…í•´ ì£¼ë“¯ì´ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_text}
                ],
                temperature=0.7
            )

            assistant_message = response.choices[0].message.content

            return {
                "assistant_message": assistant_message,
                "recommendations": [],
                "parsed_preferences": parsed_pref,
                "intent": "explain"
            }
        except Exception as e:
            logger.error(f"Explain generation failed: {e}")
            return {
                "assistant_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.",
                "recommendations": [],
                "parsed_preferences": parsed_pref,
                "intent": "error"
            }

    def generate_trend_response(
        self,
        user_text: str,
        user_profile: Dict,
        parsed_pref: Dict,
        search_context: str
    ) -> Dict:
        system_prompt = f"""
ë‹¹ì‹ ì€ ìµœì‹  K-Beauty íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì‚¬ìš©ì í”„ë¡œí•„]
- í¼ìŠ¤ë„ ì»¬ëŸ¬: {user_profile.get('tone', 'ì•Œ ìˆ˜ ì—†ìŒ')}

[ì›¹ ê²€ìƒ‰ ê²°ê³¼]
{search_context}

[ì‚¬ìš©ì ì§ˆë¬¸]
"{user_text}"

[ë‹µë³€ ê·œì¹™]
1) ë°˜ë“œì‹œ í•œêµ­ì–´(í•´ìš”ì²´)ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
2) ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì‹  íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.
3) êµ¬ì²´ì ì¸ ì œí’ˆëª…ë³´ë‹¤ëŠ” íŠ¸ë Œë“œ ê²½í–¥(ìƒ‰ìƒ, í…ìŠ¤ì²˜, ìŠ¤íƒ€ì¼ ë“±)ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
4) ì¹œê·¼í•˜ê³  ì •ë³´ì„± ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_text}
                ],
                temperature=0.7
            )

            assistant_message = response.choices[0].message.content

            return {
                "assistant_message": assistant_message,
                "recommendations": [],
                "parsed_preferences": parsed_pref,
                "intent": "trend"
            }
        except Exception as e:
            logger.error(f"Trend generation failed: {e}")
            return {
                "assistant_message": "ì£„ì†¡í•©ë‹ˆë‹¤. íŠ¸ë Œë“œ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.",
                "recommendations": [],
                "parsed_preferences": parsed_pref,
                "intent": "error"
            }