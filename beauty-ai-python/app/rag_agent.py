import os
import json
import psycopg2
from typing import Dict, List, Tuple, Optional, Any
from openai import OpenAI
import numpy as np
import uuid
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VectorDB:
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ (ì¸ì ì œê±°)
        self.vector_db_url = os.getenv("VECTOR_DATABASE_URL")
        self.general_db_url = os.getenv("DATABASE_URL")
        self.api_key = os.getenv("OPENAI_API_KEY")
        
        if not self.vector_db_url or not self.general_db_url:
            raise ValueError("ë°ì´í„°ë² ì´ìŠ¤ URL(VECTOR_DATABASE_URL, DATABASE_URL)ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        self.client = OpenAI(api_key=self.api_key)
    
    def get_vector_connection(self):
        """ë„¤ì˜¨(Vector) DB ì—°ê²°"""
        return psycopg2.connect(self.vector_db_url)

    def create_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Embedding creation failed: {e}")
            return []
    
    def save_feedback(self, feedback_id: str, user_id: str, text: str, metadata: Dict):
        """ì‚¬ìš©ì í”¼ë“œë°±(ì±„íŒ…) ì €ì¥"""
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            embedding = self.create_embedding(text)
            
            cur.execute("""
                INSERT INTO feedback_embeddings 
                (feedback_id, user_id, embedding, text, metadata)
                VALUES (%s, %s, %s, %s, %s)
            """, (
                feedback_id,
                user_id,
                embedding,
                text,
                json.dumps(metadata)
            ))
            
            conn.commit()
            cur.close()
            conn.close()
        except Exception as e:
            logger.error(f"Feedback save failed: {e}")

    def search_similar_feedbacks(self, query_text: str, user_id: str, top_k: int = 3) -> List[Dict]:
        """ìœ ì‚¬í•œ ê³¼ê±° ëŒ€í™” ê²€ìƒ‰"""
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            query_embedding = self.create_embedding(query_text)
            
            cur.execute("""
                SELECT text, metadata, embedding <=> %s::vector as distance
                FROM feedback_embeddings
                WHERE user_id = %s
                ORDER BY distance ASC
                LIMIT %s
            """, (query_embedding, user_id, top_k))
            
            results = []
            for row in cur.fetchall():
                results.append({
                    "text": row[0],
                    "metadata": row[1],
                    "distance": float(row[2])
                })
            
            cur.close()
            conn.close()
            return results
        except Exception as e:
            logger.error(f"Search feedbacks failed: {e}")
            return []

    def search_products(self, query_text: str, category: str, top_k: int = 5) -> List[Dict]:
        """
        [í•µì‹¬] ì œí’ˆ ë²¡í„° DB ê²€ìƒ‰
        """
        try:
            conn = self.get_vector_connection()
            cur = conn.cursor()
            
            # ì‚¬ìš©ìì˜ ë¶ˆë§Œ/ìš”êµ¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
            query_embedding = self.create_embedding(query_text)
            
            # ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì œí’ˆ ê²€ìƒ‰ (Cosine Distance)
            # categoryê°€ ì¼ì¹˜í•˜ëŠ” ê²ƒ ì¤‘ì—ì„œ ì°¾ìŒ
            cur.execute("""
                SELECT brand, product_name, color_name, price, text, metadata,
                       embedding <=> %s::vector as distance
                FROM product_embeddings
                WHERE category = %s
                ORDER BY distance ASC
                LIMIT %s
            """, (query_embedding, category, top_k))
            
            results = []
            for row in cur.fetchall():
                # metadataê°€ Noneì¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
                meta = row[5] if row[5] else {}
                
                results.append({
                    "brand": row[0],
                    "product_name": row[1],
                    "shade_name": row[2],
                    "price": row[3],
                    "rag_text": row[4], # DBì— ì €ì¥ëœ 'ë¦¬ë·°+íŠ¹ì§•' í…ìŠ¤íŠ¸ ë©ì–´ë¦¬
                    "metadata": meta,
                    "distance": float(row[6]),
                    "finish": meta.get("texture", "unknown") # í…ìŠ¤ì²˜ ì •ë³´ ì¶”ì¶œ
                })
            
            cur.close()
            conn.close()
            logger.info(f"ğŸ” [DB Search] Found {len(results)} products for query: '{query_text}'")
            return results
            
        except Exception as e:
            logger.error(f"Error searching products: {e}")
            return []


class IntentClassifier:
    def classify(self, text: str) -> str:
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (ë‚˜ì¤‘ì— LLMìœ¼ë¡œ ê³ ë„í™” ê°€ëŠ¥)
        if any(word in text for word in ["ì™œ", "ì´ìœ ", "ì„¤ëª…", "ë­ì•¼"]):
            return "explain"
        if any(word in text for word in ["ìœ í–‰", "íŠ¸ë Œë“œ", "ìš”ì¦˜"]):
            return "trend"
        return "recommend"

class FeedbackParser:
    def parse_feedback_to_preferences(self, text: str) -> Dict:
        """ì‚¬ìš©ì ì±„íŒ…ì—ì„œ ì„ í˜¸/ë¶ˆí˜¸ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ì´ ë²„ì „)"""
        preferences = {
            "tone": "unknown",
            "finish": "unknown",
            "like_keywords": [],
            "dislike_keywords": []
        }
        
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ íŒŒì‹±
        if "ì¿¨í†¤" in text: preferences["tone"] = "cool"
        if "ì›œí†¤" in text: preferences["tone"] = "warm"
        if "ë§¤íŠ¸" in text: preferences["finish"] = "matte"
        if "ì´‰ì´‰" in text or "ê¸€ë¡œì‹œ" in text: preferences["finish"] = "glossy"
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ì„ë² ë”© ê²€ìƒ‰ ê°•í™”ìš©)
        keywords = ["ê°ì§ˆ", "ì§€ì†ë ¥", "ë°œìƒ‰", "ì°©ìƒ‰", "ë§¤íŠ¸", "ì´‰ì´‰", "ê´‘íƒ", "ë³´ì†¡", "ì„¸ë¯¸ë§¤íŠ¸"]
        for kw in keywords:
            if kw in text:
                preferences["like_keywords"].append(kw)
                
        return preferences

class RAGAgent:
    def __init__(self, vector_db: VectorDB):
        self.vector_db = vector_db
        self.intent_classifier = IntentClassifier()
        self.feedback_parser = FeedbackParser()
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ (ë‹µë³€ ìƒì„±ìš©)
        api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key)

    def process_message(
        self,
        user_id: str,
        message: str,
        current_recommendations: List[Dict],
        user_profile: Dict,
        category: str
    ) -> Dict:
        # 1. ì˜ë„ íŒŒì•…
        intent = self.intent_classifier.classify(message)
        
        # 2. ì„ í˜¸ë„ ì¶”ì¶œ
        parsed_pref = self.feedback_parser.parse_feedback_to_preferences(message)
        
        # 3. ì‚¬ìš©ì ì±„íŒ… ì €ì¥ (ë‹¨ê¸° ê¸°ì–µìš©)
        feedback_id = str(uuid.uuid4())
        self.vector_db.save_feedback(
            feedback_id=feedback_id,
            user_id=user_id,
            text=message,
            metadata={
                "preferences": parsed_pref,
                "category": category,
                "intent": intent,
                "timestamp": str(uuid.uuid1())
            }
        )
        
        # 4. ê³¼ê±° ëŒ€í™” ë§¥ë½ ê²€ìƒ‰ (Context)
        similar_feedbacks = self.vector_db.search_similar_feedbacks(message, user_id, top_k=3)
        
        # ------------------------------------------------------------------
        # [í•µì‹¬ ë¡œì§ ìˆ˜ì •] ì—„ê²©í•œ í•„í„°ë§ ì œê±°í•˜ê³  DB ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‹ ë¢°í•¨
        # ------------------------------------------------------------------
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥: ì‚¬ìš©ì ì§ˆë¬¸ + ì¶”ì¶œëœ í‚¤ì›Œë“œ
        search_query = f"{message} {' '.join(parsed_pref['like_keywords'])}"
        
        # [ìˆ˜ì • 1] ê²€ìƒ‰ ê°œìˆ˜(top_k)ë¥¼ 6ê°œë¡œ ëŠ˜ë¦¼ (í›„ë³´êµ° í™•ë³´)
        db_products = self.vector_db.search_products(
            query_text=search_query, 
            category=category, 
            top_k=6 
        )
        
        # [ìˆ˜ì • 2] íŒŒì´ì¬ í•„í„°ë§(Reranker) ì œê±° -> LLMì—ê²Œ íŒë‹¨ ìœ„ì„
        # DBê°€ ì´ë¯¸ 'ì˜ë¯¸ì ìœ¼ë¡œ' ê°€ì¥ ê°€ê¹Œìš´ê±¸ ì°¾ì•„ì™”ìœ¼ë¯€ë¡œ(ì˜ˆ: ì„¸ë¯¸ë§¤íŠ¸), ê·¸ëŒ€ë¡œ ë„˜ê¹ë‹ˆë‹¤.
        final_candidates = db_products
        
        # ë§Œì•½ DB ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´(0ê°œ), ê¸°ì¡´ ì¶”ì²œ ëª©ë¡ì´ë¼ë„ ë„£ì–´ì„œ ëŒ€í™”ê°€ ëŠê¸°ì§€ ì•Šê²Œ í•¨
        if not final_candidates and current_recommendations:
             # current_recommendations í˜•ì‹ì„ db_products í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨ (ì•½ì‹ ì²˜ë¦¬)
             for item in current_recommendations:
                 final_candidates.append({
                     "brand": item.get("brand", ""),
                     "product_name": item.get("product_name", ""),
                     "shade_name": item.get("shade_name", ""),
                     "rag_text": f"{item.get('brand')} {item.get('product_name')}. ê¸°ì¡´ ì¶”ì²œ ì œí’ˆì…ë‹ˆë‹¤.",
                     "price": item.get("price", 0)
                 })

        # 5. LLM ë‹µë³€ ìƒì„±
        return self.generate_explanation(
            user_text=message,
            user_profile=user_profile,
            parsed_pref=parsed_pref,
            memories=similar_feedbacks,
            candidate_products=final_candidates
        )

    def generate_explanation(
        self,
        user_text: str,
        user_profile: Dict,
        parsed_pref: Dict,
        memories: List[Dict],
        candidate_products: List[Dict]
    ) -> Dict:
        
        # í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ì œí’ˆ ëª©ë¡ í…ìŠ¤íŠ¸ ìƒì„±
        if candidate_products:
            products_context = "\n".join([
                f"""
                [ì œí’ˆ {idx+1}]
                - ë¸Œëœë“œ: {p['brand']}
                - ì´ë¦„: {p['product_name']} ({p['shade_name']})
                - ê°€ê²©: {p['price']}ì›
                - ìƒì„¸ì •ë³´/ë¦¬ë·°ìš”ì•½: {p.get('rag_text', 'ì •ë³´ ì—†ìŒ')}
                """ for idx, p in enumerate(candidate_products)
            ])
        else:
            products_context = "ê²€ìƒ‰ëœ ì í•©í•œ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        # ------------------------------------------------------------------
        # [ìˆ˜ì • 3] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: "ì¤‘ì¬ì ëª¨ë“œ" ê°•í™”
        # ------------------------------------------------------------------
        system_prompt = f"""
        ë‹¹ì‹ ì€ ìœµí†µì„± ìˆê³  ì„¤ë“ë ¥ ìˆëŠ” K-Beauty AI ë·°í‹° ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
        ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , í¼ìŠ¤ë„ ì»¬ëŸ¬ ì „ë¬¸ê°€ì²˜ëŸ¼ ì‚¬ìš©ìë¥¼ ì„¤ë“í•˜ì„¸ìš”.

        [ì‚¬ìš©ì í”„ë¡œí•„]
        - í¼ìŠ¤ë„ ì»¬ëŸ¬: {user_profile.get('tone', 'ì•Œ ìˆ˜ ì—†ìŒ')}
        - ì„ í˜¸ ë¸Œëœë“œ: {', '.join(user_profile.get('fav_brands', []))}
        - ì„ í˜¸ í”¼ë‹ˆì‹œ: {', '.join(user_profile.get('finish_preference', []))}
        
        [ê²€ìƒ‰ëœ í›„ë³´ ì œí’ˆ ëª©ë¡ (DB ê¸°ë°˜)]
        {products_context}
        
        [ì‚¬ìš©ì ì§ˆë¬¸/ë¶ˆë§Œ]
        "{user_text}"
        
        [í–‰ë™ ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)]
        1. **'ì¶”ì²œ ë¶ˆê°€'ë¼ê³  ë§í•˜ì§€ ë§ˆì„¸ìš”.** í›„ë³´ ì œí’ˆ ëª©ë¡ ì¤‘ì—ì„œ ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­(í…ìŠ¤ì²˜, ìƒ‰ê° ë“±)ì— **ê°€ì¥ ê·¼ì ‘í•œ 1~3ê°œ**ë¥¼ ë°˜ë“œì‹œ ê³¨ë¼ë‚´ì„¸ìš”.
        
        2. ì‚¬ìš©ì í”„ë¡œí•„ì—ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ {user_profile.tone}ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
        í•˜ì§€ë§Œ ì‚¬ìš©ìê°€ ëŒ€í™” ì¤‘ ë‹¤ìŒê³¼ ê°™ì€ ì˜ë„ë¥¼ ë³´ì´ë©´ â€˜í†¤ í¬ë¡œìŠ¤(Tone-Cross)â€™ ì¶”ì²œì„ í—ˆìš©í•˜ì„¸ìš”:

        - "ì¿¨í†¤ ì œí’ˆë„ ê´œì°®ì•„ìš”."
        - "ì›œí†¤ì´ì§€ë§Œ ì¿¨ ëŠë‚Œë„ ì¨ë³´ê³  ì‹¶ì–´ìš”."
        - "í†¤ ìƒê´€ì—†ì´ ì˜ˆìœ ìƒ‰ ì¶”ì²œí•´ì¤˜."
        - "ë‹¤ë¥¸ í†¤ë„ ì œì•ˆí•´ì¤˜."

        í†¤ í¬ë¡œìŠ¤ ìƒí™©ì—ì„œëŠ” ë‹¤ìŒ ì›ì¹™ì„ ë”°ë¥´ì„¸ìš”:

        1. **ì‚¬ìš©ìê°€ ì›í•œ í†¤(ì˜ˆ: ì¿¨í†¤)ì„ ìš°ì„ ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.**
        2. **ë‹¨, ê¸°ì¡´ ì‚¬ìš©ì í”„ë¡œí•„(ì˜ˆ: ì›œí†¤)ê³¼ ë‹¤ë¥¸ í†¤ì„ ì¶”ì²œí•  ë•ŒëŠ” ë°˜ë“œì‹œ ì™œ ì–´ìš¸ë¦¬ëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.**
           - ì˜ˆ: â€œê³ ê°ë‹˜ì€ ì›œí†¤ì´ì§€ë§Œ ì´ ì¿¨ í•‘í¬ëŠ” ì±„ë„ê°€ ë‚®ê³  ì•½ê°„ ê·¸ë ˆì´ì‹œí•´ì„œ ì›œí†¤ë„ ë°ì¼ë¦¬ë¡œ ì“°ê¸° ì¢‹ì•„ìš”!â€
        3. **ëª…ë„Â·ì±„ë„Â·ì–¸ë”í†¤Â·í…ìŠ¤ì²˜ë¥¼ ê·¼ê±°ë¡œ ì„¤ë“ë ¥ ìˆê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.**
        4. **ì‚¬ìš©ìê°€ Tone-Crossê°€ ë¶ˆí¸í•´í•œë‹¤ë©´ ì¦‰ì‹œ ê¸°ë³¸ í†¤ìœ¼ë¡œ ë˜ëŒì•„ê°‘ë‹ˆë‹¤.**

        ì´ ê·œì¹™ì„ ëª¨ë“  ì¶”ì²œ ë‹µë³€ì—ì„œ í•­ìƒ ì ìš©í•˜ì„¸ìš”.

        3. **ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.**
           - ì œí’ˆ ì •ë³´(rag_text)ì— ìˆëŠ” "ê°ì§ˆ ë¶€ê° ì—†ìŒ", "ì§€ì†ë ¥ ì¢‹ìŒ" ë“±ì˜ ë©˜íŠ¸ë¥¼ ì¸ìš©í•´ì„œ ì¶”ì²œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
           
        4. ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ê³µê°í•˜ëŠ” ë§íˆ¬(í•´ìš”ì²´)ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_text}
                ],
                temperature=0.7 # ì°½ì˜ì„± ì•½ê°„ ë†’ì„ (ì„¤ë“ì„ ìœ„í•´)
            )
            
            assistant_message = response.choices[0].message.content
            
            return {
                "assistant_message": assistant_message,
                "recommendations": candidate_products[:3], # ìƒìœ„ 3ê°œ ì •ë³´ë¥¼ í”„ë¡ íŠ¸ì— ì „ë‹¬
                "parsed_preferences": parsed_pref,
                "intent": "recommend"
            }
            
        except Exception as e:
            logger.error(f"LLM generation failed: {e}")
            return {
                "assistant_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.",
                "recommendations": [],
                "parsed_preferences": parsed_pref,
                "intent": "error"
            }